{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore  the warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('always')\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install imblearn "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Relevant Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "import re, os\n",
    "import string \n",
    "from nltk.tokenize import  word_tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import precision_score, accuracy_score, recall_score, f1_score, confusion_matrix,classification_report\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.linear_model import SGDClassifier, SGDRegressor\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pickle\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import chi2, SelectKBest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data\n",
    "data_file = 'Amazon_Unlocked_Mobile.csv'\n",
    "data_raw = pd.read_csv( data_file, delimiter = \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Product Name', 'Brand Name', 'Price', 'Rating', 'Reviews',\n",
       "       'Review Votes'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=data_raw.copy()\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['Reviews'].isnull()==False]#remove any blank reviews\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['word_count'] = [len(review.split()) for review in data['Reviews']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[131147    SUPPLEMENTAL USER GUIDE for BLU Pure XLBLU's o...\n",
       " 131639    SUPPLEMENTAL USER GUIDE for BLU Pure XLBLU's o...\n",
       " Name: Reviews, dtype: object]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_review=[data[data['word_count']== 5313].Reviews]\n",
    "max_review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can notice these two rows are showing user guide so we can remove them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['word_count']<150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def review_to_wordlist( review, remove_stopwords=True):\n",
    "    # Function to convert a document to a sequence of words,\n",
    "    # optionally removing stop words.  Returns a list of words.\n",
    "    #\n",
    "    # 1. Remove HTML\n",
    "    review_text = BeautifulSoup(review).get_text()\n",
    "\n",
    "    #\n",
    "    # 2. Remove non-letters\n",
    "    review_text = re.sub(\"[^a-zA-Z]\",\" \", review)\n",
    "    #\n",
    "    # 3. Convert words to lower case and split them\n",
    "    words = review_text.lower().split()\n",
    "    #\n",
    "    # 4. Optionally remove stop words (True by default)\n",
    "    if remove_stopwords:\n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        words = [w for w in words if not w in stops]\n",
    "\n",
    "    b=[]\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    for word in words:\n",
    "        b.append(lemmatizer.lemmatize(word))\n",
    "\n",
    "    # 5. Return a list of words\n",
    "    return(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X =data['Reviews']\n",
    "y = data['Rating']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_train = []\n",
    "for review in X_train:\n",
    "    clean_train.append( \" \".join(review_to_wordlist(review)))\n",
    "clean_val = []\n",
    "for review in X_val:\n",
    "    clean_val.append( \" \".join(review_to_wordlist(review)))\n",
    "    \n",
    "clean_test = []\n",
    "for review in X_test:\n",
    "    clean_test.append( \" \".join(review_to_wordlist(review)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF-IDF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfvec = TfidfVectorizer(ngram_range=(1, 3),max_features=200000,stop_words='english',token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tfidfvec= tfidfvec.fit(clean_train)\n",
    "clean_train_tf = tfidfvec.transform(clean_train)\n",
    "\n",
    "clean_val_tf = tfidfvec.transform(clean_val)\n",
    "clean_test_tf = tfidfvec.transform(clean_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multinomial Naive Bayes Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb=MultinomialNB(alpha=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SGD Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd=SGDClassifier(loss='modified_huber', max_iter=5, random_state=0, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Classifier Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "rfc=RandomForestClassifier(verbose =3,n_estimators=45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdaBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "adc=AdaBoostClassifier(random_state=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model=XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=0.001, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb.fit( clean_train_tf, y_train )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline2.fit( X_train, y_train )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='modified_huber', max_iter=5,\n",
       "       n_iter=None, n_jobs=1, penalty='l2', power_t=0.5, random_state=0,\n",
       "       shuffle=True, tol=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd.fit( clean_train_tf, y_train )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.fit(clean_train_tf, y_train )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
       "          learning_rate=1.0, n_estimators=100, random_state=None)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adc.fit( clean_train_tf, y_train )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model.fit(clean_train_tf, y_train )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds1 = mnb.predict(clean_val_tf)#mnb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds2 = pipeline1.predict(X_val)#svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds3 = sgd.predict(clean_val_tf)#sgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds4 = rfc.predict(clean_val_tf)#rfc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds5 =adc.predict(clean_val_tf)#adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "preds6 = xgb_model.predict(clean_val_tf)#xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.81      0.86      0.84     22806\n",
      "          2       0.81      0.53      0.64      7427\n",
      "          3       0.79      0.51      0.62      9796\n",
      "          4       0.74      0.45      0.56     18638\n",
      "          5       0.82      0.96      0.89     70849\n",
      "\n",
      "avg / total       0.81      0.81      0.80    129516\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from  sklearn.metrics import classification_report,accuracy_score\n",
    "print(classification_report(y_val, preds1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(classification_report(y_train, preds2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.90      0.78     22806\n",
      "          2       0.86      0.20      0.32      7427\n",
      "          3       0.80      0.24      0.37      9796\n",
      "          4       0.67      0.23      0.34     18638\n",
      "          5       0.78      0.97      0.86     70849\n",
      "\n",
      "avg / total       0.75      0.75      0.71    129516\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_val, preds3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.81      0.91      0.86     22806\n",
      "          2       0.92      0.63      0.75      7427\n",
      "          3       0.89      0.61      0.73      9796\n",
      "          4       0.88      0.55      0.68     18638\n",
      "          5       0.86      0.97      0.91     70849\n",
      "\n",
      "avg / total       0.86      0.85      0.84    129516\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_val, preds4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.59      0.73      0.65     22806\n",
      "          2       0.23      0.01      0.03      7427\n",
      "          3       0.37      0.08      0.14      9796\n",
      "          4       0.39      0.09      0.15     18638\n",
      "          5       0.71      0.94      0.81     70849\n",
      "\n",
      "avg / total       0.59      0.66      0.59    129516\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_val, preds5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.68      0.78      0.73     22806\n",
      "          2       0.79      0.16      0.27      7427\n",
      "          3       0.70      0.20      0.32      9796\n",
      "          4       0.58      0.19      0.28     18638\n",
      "          5       0.74      0.97      0.84     70849\n",
      "\n",
      "avg / total       0.71      0.72      0.67    129516\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_val, preds6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 1 accuracy:  0.812494209209673\n",
      "model 3 accuracy:  0.7536134531640878\n",
      "model 4 accuracy:  0.8534852836715154\n",
      "model 5 accuracy:  0.6616093764476976\n",
      "model 6 accuracy:  0.7182510269001513\n"
     ]
    }
   ],
   "source": [
    "print('model 1 accuracy: ', accuracy_score(y_val, preds1))\n",
    "# print('model2 accuracy: ', accuracy_score(y_val, preds2))\n",
    "print('model 3 accuracy: ', accuracy_score(y_val, preds3))\n",
    "print('model 4 accuracy: ', accuracy_score(y_val, preds4))\n",
    "print('model 5 accuracy: ', accuracy_score(y_val, preds5))\n",
    "print('model 6 accuracy: ', accuracy_score(y_val, preds6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_resampled, y_train_resampled = SMOTE(random_state = 2).fit_sample(clean_train_tf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=0.001, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb.fit( X_train_resampled, y_train_resampled )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "              l1_ratio=0.15, learning_rate='optimal', loss='modified_huber',\n",
       "              max_iter=5, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
       "              power_t=0.5, random_state=0, shuffle=True, tol=0.001,\n",
       "              validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd.fit( X_train_resampled, y_train_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  3.4min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 2 of 45\n"
     ]
    }
   ],
   "source": [
    "rfc.fit(X_train_resampled, y_train_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,\n",
       "                   n_estimators=50, random_state=2)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adc.fit( X_train_resampled, y_train_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='multi:softprob', random_state=0, reg_alpha=0,\n",
       "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
       "              tree_method=None, validate_parameters=False, verbosity=None)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model.fit( X_train_resampled, y_train_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds1_smote = mnb.predict(clean_val_tf)#mnb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds3_smote =sgd.predict(clean_val_tf)#sgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  45 out of  45 | elapsed:   12.1s finished\n"
     ]
    }
   ],
   "source": [
    "preds4_smote = rfc.predict(clean_val_tf)#rfc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds5_smote = adc.predict(clean_val_tf)#adc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds6_smote = xgb_model.predict(clean_val_tf)#xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.84      0.82     22806\n",
      "           2       0.62      0.63      0.62      7427\n",
      "           3       0.61      0.60      0.60      9796\n",
      "           4       0.51      0.62      0.56     18638\n",
      "           5       0.89      0.82      0.85     70849\n",
      "\n",
      "    accuracy                           0.77    129516\n",
      "   macro avg       0.68      0.70      0.69    129516\n",
      "weighted avg       0.78      0.77      0.77    129516\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_val, preds1_smote))#mnb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.83      0.79     22806\n",
      "           2       0.43      0.56      0.48      7427\n",
      "           3       0.49      0.50      0.50      9796\n",
      "           4       0.50      0.47      0.48     18638\n",
      "           5       0.87      0.83      0.85     70849\n",
      "\n",
      "    accuracy                           0.74    129516\n",
      "   macro avg       0.61      0.64      0.62    129516\n",
      "weighted avg       0.74      0.74      0.74    129516\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_val, preds3_smote))#sgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.81      0.93      0.87     22806\n",
      "           2       0.85      0.66      0.74      7427\n",
      "           3       0.75      0.66      0.70      9796\n",
      "           4       0.62      0.68      0.65     18638\n",
      "           5       0.90      0.88      0.89     70849\n",
      "\n",
      "    accuracy                           0.83    129516\n",
      "   macro avg       0.79      0.76      0.77    129516\n",
      "weighted avg       0.83      0.83      0.83    129516\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_val, preds4_smote))#RFC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 4 rfc accuracy with SMOTE:  0.8290944748139226\n"
     ]
    }
   ],
   "source": [
    "print('model 4 rfc accuracy with SMOTE: ',accuracy_score(y_val, preds4_smote))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.44      0.73      0.55     22806\n",
      "           2       0.17      0.19      0.18      7427\n",
      "           3       0.21      0.17      0.19      9796\n",
      "           4       0.27      0.34      0.30     18638\n",
      "           5       0.83      0.62      0.71     70849\n",
      "\n",
      "    accuracy                           0.54    129516\n",
      "   macro avg       0.38      0.41      0.38    129516\n",
      "weighted avg       0.60      0.54      0.55    129516\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_val, preds5_smote))#ADABoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.67      0.79      0.72     22806\n",
      "           2       0.28      0.43      0.34      7427\n",
      "           3       0.44      0.37      0.40      9796\n",
      "           4       0.37      0.48      0.42     18638\n",
      "           5       0.86      0.72      0.78     70849\n",
      "\n",
      "    accuracy                           0.65    129516\n",
      "   macro avg       0.52      0.56      0.53    129516\n",
      "weighted avg       0.69      0.65      0.67    129516\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_val, preds6_smote))#XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 1(sgd classifier) accuracy with SMOTE:  0.7684842027239878\n",
      "model 3 accuracy with SMOTE:  0.7358241452793477\n",
      "model 4 accuracy with SMOTE:  0.8240063003798759\n",
      "model 5 accuracy with SMOTE:  0.5367676580499706\n",
      "model 6 accuracy with SMOTE:  0.652668396182711\n"
     ]
    }
   ],
   "source": [
    "print('model 1(mnb classifier) accuracy with SMOTE: ', accuracy_score(y_val, preds1_smote))\n",
    "# print('model2 accuracy: ', metrics.accuracy_score(y_val, preds2))\n",
    "print('model 3sgd accuracy with SMOTE: ', accuracy_score(y_val, preds3_smote))\n",
    "print('model 4 rfc accuracy with SMOTE: ',accuracy_score(y_val, preds4_smote))\n",
    "print('model 5 adaboost accuracy with SMOTE: ', accuracy_score(y_val, preds5_smote))\n",
    "print('model 6  XGB accuracy with SMOTE: ', accuracy_score(y_val, preds6_smote))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "fselect = SelectKBest(chi2 , k=10000)\n",
    "train_features = fselect.fit_transform(clean_train_tf,y_train )\n",
    "val_features= fselect.transform(clean_val_tf)\n",
    "test_features = fselect.transform(clean_test_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=0.001, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb.fit( train_features, y_train )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc.fit( train_features, y_train )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "              l1_ratio=0.15, learning_rate='optimal', loss='modified_huber',\n",
       "              max_iter=5, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
       "              power_t=0.5, random_state=0, shuffle=True, tol=0.001,\n",
       "              validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd.fit( train_features, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   11.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 2 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   22.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 3 of 20\n",
      "building tree 4 of 20\n",
      "building tree 5 of 20\n",
      "building tree 6 of 20\n",
      "building tree 7 of 20\n",
      "building tree 8 of 20\n",
      "building tree 9 of 20\n",
      "building tree 10 of 20\n",
      "building tree 11 of 20\n",
      "building tree 12 of 20\n",
      "building tree 13 of 20\n",
      "building tree 14 of 20\n",
      "building tree 15 of 20\n",
      "building tree 16 of 20\n",
      "building tree 17 of 20\n",
      "building tree 18 of 20\n",
      "building tree 19 of 20\n",
      "building tree 20 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:  3.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=20,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=3, warm_start=False)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.fit( train_features, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,\n",
       "                   n_estimators=50, random_state=2)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adc.fit( train_features, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='multi:softprob', random_state=0, reg_alpha=0,\n",
       "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
       "              tree_method=None, validate_parameters=False, verbosity=None)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model.fit( train_features, y_train )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds1_featselect = mnb.predict(val_features)#mnb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds2_featselect = svc.predict(val_features)# svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds3_featselect = sgd.predict(val_features)#SGD classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:    2.4s finished\n"
     ]
    }
   ],
   "source": [
    "preds4_featselect = rfc.predict(val_features)#random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds5_featselect = adc.predict(val_features)#adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds6_featselect = xgb_model.predict(val_features)#xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.68      0.76      0.72     22806\n",
      "           2       0.83      0.19      0.31      7427\n",
      "           3       0.77      0.17      0.28      9796\n",
      "           4       0.54      0.11      0.18     18638\n",
      "           5       0.72      0.98      0.83     70849\n",
      "\n",
      "    accuracy                           0.71    129516\n",
      "   macro avg       0.71      0.44      0.46    129516\n",
      "weighted avg       0.70      0.71      0.64    129516\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_val, preds1_featselect))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.65      0.83      0.73     22806\n",
      "           2       0.82      0.11      0.19      7427\n",
      "           3       0.71      0.12      0.21      9796\n",
      "           4       0.48      0.11      0.18     18638\n",
      "           5       0.73      0.97      0.84     70849\n",
      "\n",
      "    accuracy                           0.71    129516\n",
      "   macro avg       0.68      0.43      0.43    129516\n",
      "weighted avg       0.69      0.71      0.64    129516\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_val, preds3_featselect))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.91      0.87     22806\n",
      "           2       0.92      0.64      0.76      7427\n",
      "           3       0.90      0.62      0.73      9796\n",
      "           4       0.85      0.56      0.68     18638\n",
      "           5       0.86      0.97      0.91     70849\n",
      "\n",
      "    accuracy                           0.86    129516\n",
      "   macro avg       0.87      0.74      0.79    129516\n",
      "weighted avg       0.86      0.86      0.85    129516\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_val, preds4_featselect))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.53      0.68      0.60     22806\n",
      "           2       0.24      0.00      0.01      7427\n",
      "           3       0.40      0.07      0.11      9796\n",
      "           4       0.34      0.05      0.08     18638\n",
      "           5       0.68      0.93      0.79     70849\n",
      "\n",
      "    accuracy                           0.64    129516\n",
      "   macro avg       0.44      0.35      0.32    129516\n",
      "weighted avg       0.56      0.64      0.56    129516\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_val, preds5_featselect))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.68      0.78      0.73     22806\n",
      "           2       0.81      0.16      0.26      7427\n",
      "           3       0.69      0.20      0.31      9796\n",
      "           4       0.58      0.19      0.28     18638\n",
      "           5       0.74      0.97      0.84     70849\n",
      "\n",
      "    accuracy                           0.72    129516\n",
      "   macro avg       0.70      0.46      0.48    129516\n",
      "weighted avg       0.70      0.72      0.66    129516\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_val, preds6_featselect))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 1(mnb classifier) accuracy with feature selection:  0.708298588591371\n",
      "model 3sgd accuracy with feature selection:  0.7065845146545601\n",
      "model 4 rfc accuracy with feature selection:  0.8563111893511226\n",
      "model 5 adaboost accuracy with feature selection:  0.6397356311189352\n",
      "model 6  XGB accuracy with feature selection:  0.7170002161895055\n"
     ]
    }
   ],
   "source": [
    "print('model 1(mnb classifier) accuracy with feature selection: ', accuracy_score(y_val, preds1_featselect))\n",
    "# print('model2 accuracy: ', metrics.accuracy_score(y_val, preds2))\n",
    "print('model 3sgd accuracy with feature selection: ', accuracy_score(y_val, preds3_featselect))\n",
    "print('model 4 rfc accuracy with feature selection: ',accuracy_score(y_val, preds4_featselect))\n",
    "print('model 5 adaboost accuracy with feature selection: ', accuracy_score(y_val, preds5_featselect))\n",
    "print('model 6  XGB accuracy with feature selection: ', accuracy_score(y_val, preds6_featselect))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can conclude Random Forest Model is performing best in term of metrics. It will be our main model and we will perform gride search to further improve its performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Selection with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "fselect = SelectKBest(chi2 , k=10000)\n",
    "train_features = fselect.fit_transform(X_train_resampled, y_train_resampled)\n",
    "val_features= fselect.transform(clean_val_tf)\n",
    "test_features = fselect.transform(clean_test_tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search CV with cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 27 candidates, totalling 81 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# Create the parameter grid based on the results of random search \n",
    "bootstrap = [False]\n",
    "max_depth = [30, 40, 50]\n",
    "max_features = ['sqrt']\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "min_samples_split = [5, 10, 15]\n",
    "n_estimators = [100]\n",
    "\n",
    "param_grid = {\n",
    "    'bootstrap': bootstrap,\n",
    "    'max_depth': max_depth,\n",
    "    'max_features': max_features,\n",
    "    'min_samples_leaf': min_samples_leaf,\n",
    "    'min_samples_split': min_samples_split,\n",
    "    'n_estimators': n_estimators\n",
    "}\n",
    "\n",
    "# Create a base model\n",
    "rfc = RandomForestClassifier(random_state=8)\n",
    "\n",
    "# Manually create the splits in CV in order to be able to fix a random_state (GridSearchCV doesn't have that argument)\n",
    "cv_sets = ShuffleSplit(n_splits = 3, test_size = .33, random_state = 8)\n",
    "\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator=rfc, \n",
    "                           param_grid=param_grid,\n",
    "                           scoring='accuracy',\n",
    "                           cv=cv_sets,\n",
    "                           verbose=1)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(train_features, y_train_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### best parameters turn out to be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The best hyperparameters from Grid Search are:\")\n",
    "print(grid_search.best_params_)\n",
    "print(\"\")\n",
    "print(\"The mean accuracy of a model with these hyperparameters is:\")\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rfc = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model fit and performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rfc.fit(train_features, y_train_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_pred = best_rfc.predict(test_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training accuracy\n",
    "print(\"The training accuracy is: \")\n",
    "print(accuracy_score(y_train_resampled, best_rfc.predict(train_features)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test accuracy\n",
    "print(\"The test accuracy is: \")\n",
    "print(accuracy_score(y_test, rfc_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
